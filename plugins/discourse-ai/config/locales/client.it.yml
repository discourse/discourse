# WARNING: Never edit this file.
# It will be overwritten when translations are pulled from Crowdin.
#
# To work with us on translations, join this project:
# https://translate.discourse.org/

it:
  admin_js:
    admin:
      api:
        scopes:
          descriptions:
            discourse_ai:
              search: "Consente la ricerca IA"
              stream_completion: "Consente lo streaming di completamenti di personaggi IA"
              update_personas: "Consente l'aggiornamento dei personaggi IA"
      site_settings:
        categories:
          discourse_ai: "Discourse AI"
      dashboard:
        emotion:
          title: "Emozione"
          description: "La tabella elenca un conteggio di messaggi classificati con un'emozione determinata. Classificati con il modello 'SamLowe/roberta-base-go_emotions'."
        reports:
          filters:
            group_by:
              label: "Raggruppa per"
            sort_by:
              label: "Ordina per"
            tag:
              label: "Etichetta"
      logs:
        staff_actions:
          actions:
            create_ai_llm_model: "Crea modello LLM"
            update_ai_llm_model: "Aggiorna modello LLM"
            delete_ai_llm_model: "Elimina modello LLM"
            create_ai_persona: "Crea personaggio IA"
            update_ai_persona: "Aggiorna personaggio IA"
            delete_ai_persona: "Elimina personaggio IA"
            create_ai_tool: "Crea strumento IA"
            update_ai_tool: "Aggiorna strumento IA"
            delete_ai_tool: "Elimina strumento IA"
            create_ai_embedding: "Crea integrazione IA"
            update_ai_embedding: "Aggiorna integrazione IA"
            delete_ai_embedding: "Elimina integrazione IA"
            update_ai_spam_settings: "Aggiorna impostazioni anti-spam IA"
  js:
    discourse_automation:
      scriptables:
        llm_report:
          fields:
            sender:
              label: "Mittente"
              description: "L'utente che invierà il report"
            receivers:
              label: "Destinatari"
              description: "Gli utenti che riceveranno il report (le email saranno inviate direttamente, i nomi utente riceveranno un messaggio privato)"
            topic_id:
              label: "ID dell'argomento"
              description: "L'ID dell'argomento in cui pubblicare il report"
            title:
              label: "Titolo"
              description: "Il titolo del report"
            days:
              label: "Giorni"
              description: "L'arco temporale del report"
            offset:
              label: "Scostamento"
              description: "Durante il test, potresti voler eseguire il report in modo cronologico, utilizza lo scostamento per avviare il report in una data precedente"
            instructions:
              label: "Istruzioni"
              description: "Le istruzioni fornite al large language model"
            sample_size:
              label: "Dimensione del campione"
              description: "Il numero di messaggi da campionare per il report"
            tokens_per_post:
              label: "Token per messaggio"
              description: "Il numero di token LLM da utilizzare per messaggio"
            model:
              label: "Modello"
              description: "LLM da utilizzare per la generazione del report"
            categories:
              label: "Categorie"
              description: "Filtra gli argomenti solo in queste categorie"
            tags:
              label: "Etichette"
              description: "Filtra gli argomenti solo in base a queste etichette"
            exclude_tags:
              label: "Escludi etichette"
              description: "Escludi argomenti con queste etichette"
            exclude_categories:
              label: "Escludi categorie"
              description: "Escludi argomenti con queste categorie"
            allow_secure_categories:
              label: "Consenti categorie sicure"
              description: "Consenti la generazione del report per argomenti in categorie sicure"
            suppress_notifications:
              label: "Evita le notifiche"
              description: "Evita le notifiche che il report potrebbe generare trasformandosi in contenuto. Ciò rimapperà le menzioni e i link interni."
            debug_mode:
              label: "Modalità di debug"
              description: "Abilita la modalità di debug per visualizzare input e output non elaborati del LLM"
            priority_group:
              label: "Gruppo prioritario"
              description: "Dai la priorità ai contenuti di questo gruppo nel report"
            temperature:
              label: "Temperatura"
              description: "Temperatura da utilizzare per il LLM. Aumentala per aumentare la casualità (lascia il campo vuoto per utilizzare il modello predefinito)"
            top_p:
              label: "P superiore"
              description: "P superiore da utilizzare per il LLM, aumentala per aumentare la casualità (lascia il campo vuoto per utilizzare il modello predefinito)"
            persona_id:
              label: "Personaggio"
              description: "Personaggio IA da usare per la generazione del report"
        llm_tool_triage:
          fields:
            model:
              label: "Modello"
              description: "Il modello linguistico predefinito utilizzato per il triage"
            tool:
              label: "Strumento"
              description: "Strumento da utilizzare per il triage (lo strumento non deve avere parametri definiti)"
        llm_persona_triage:
          fields:
            persona:
              label: "Personaggio"
              description: "Personaggio IA da utilizzare per il triage (devono essere impostati LLM e utente predefiniti)"
            whisper:
              label: "Rispondi come sussurro"
              description: "Seleziona se ricevere la risposta del personaggio come sussurro"
            silent_mode:
              label: "Modalità silenziosa"
              description: "In modalità silenziosa, il personaggio riceverà il contenuto ma non pubblicherà nulla sul forum. Impostazione utile quando si esegue il triage utilizzando gli strumenti"
        llm_triage:
          fields:
            triage_persona:
              label: "Personaggio"
              description: "Personaggio utilizzato per il triage, assicurati che risponda con una sola parola che puoi usare per attivare l'azione"
            max_post_tokens:
              label: "Numero massimo di token di messaggio"
              description: "Numero massimo di token per scansionare utilizzando il triage LLM"
            stop_sequences:
              label: "Sequenze di arresto"
              description: "Indica al modello di interrompere la generazione del token quando si arriva a uno di questi valori"
            search_for_text:
              label: "Cerca testo"
              description: "Se nella risposta del LLM viene visualizzato il testo seguente, applica queste azioni"
            category:
              label: "Categoria"
              description: "Categoria da applicare all'argomento"
            tags:
              label: "Etichette"
              description: "Etichette da applicare all'argomento"
            canned_reply:
              label: "Rispondi"
              description: "Testo non elaborato della risposta predefinita al messaggio sull'argomento"
            canned_reply_user:
              label: "Utente della risposta"
              description: "Nome utente dell'utente che pubblicherà la risposta predefinita"
            hide_topic:
              label: "Nascondi argomento"
              description: "Rendi l'argomento non visibile al pubblico se attivato"
            flag_type:
              label: "Tipo di segnalazione"
              description: "Tipo di segnalazione da applicare al messaggio (spam o semplicemente passa in revisione)"
            flag_post:
              label: "Segnala messaggio"
              description: "Segnala il messaggio (come spam o per la revisione)"
            include_personal_messages:
              label: "Includi messaggi personali"
              description: "Esegui anche la scansione e la selezione dei messaggi personali"
            whisper:
              label: "Rispondi come sussurro"
              description: "Seleziona se ricevere la risposta dell'IA come sussurro"
            reply_persona:
              label: "Personaggio che risponde"
              description: "Personaggio IA da utilizzare per le risposte (deve avere LLM predefinito). Ha la priorità rispetto alla risposta predefinita"
            max_output_tokens:
              label: "Massimo token di output"
              description: "Quando viene specificato un valore, imposta il limite massimo del numero di token generabili dal modello. Rispetta il limite massimo di token di output del LLM"
    discourse_ai:
      title: "IA"
      default_llm:
        title: "Modello LLM predefinito"
        description: "Modello LLM predefinito da utilizzare per tutte le funzionalità IA. Verrà utilizzato se non è specificato alcun LLM nella configurazione della funzionalità o del personaggio. Se non è specificato alcun LLM predefinito, verrà utilizzato l'ultimo LLM creato."
      features:
        short_title: "Funzionalità"
        description: "Le funzionalità IA a disposizione dei visitatori del tuo sito web. Possono essere configurate utilizzando personaggi e LLM specifici. I gruppi possono controllarne l'accesso."
        back: "Indietro"
        disabled: "(disabilitati)"
        persona:
          one: "Personaggio:"
          other: "Personaggi:"
        groups: "Gruppi:"
        llm:
          one: "LLM:"
          other: "LLM:"
        no_llm: "Nessun LLM selezionato"
        no_persona: "Non impostato"
        no_groups: "Nessuna"
        edit: "Modifica"
        expand_list:
          one: "(%{count} altro)"
          other: "(altri %{count})"
        collapse_list: "(mostra meno)"
        bot:
          bot: "Chatbot"
          name: "Bot"
          description: "Un chatbot in grado di rispondere alle domande e assistere gli utenti nei messaggi personali, nei forum e in chat"
        nav:
          configured: "Configurate"
          unconfigured: "Non configurate"
        filters:
          all: "Tutte"
          text: "Cerca funzionalità, personaggi, LLM o gruppi..."
          no_results: "Nessuna funzionalità trovata per i filtri impostati."
          reset: "Annulla"
        no_automations: "Non ci sono ancora automazioni"
        summarization:
          name: "Riepiloghi"
          description: "Rende disponibile un pulsante attraverso cui i visitatori possono ottenere un riepilogo degli argomenti"
          topic_summaries: "Riepiloghi degli argomenti"
          gists: "Mini riepiloghi dell'elenco argomenti"
        search:
          name: "Cerca"
          description: "Migliora l'esperienza di ricerca rispondendo alle query con risposte generate con l'IA"
          discoveries: "Scoperte"
        embeddings:
          name: "Integrazioni"
          description: "Sono alla base di funzionalità come Argomenti correlati e Ricerca IA generando rappresentazioni semantiche di un testo"
          hyde: "HyDE"
        discord:
          name: "Integrazione Discord"
          description: "Aggiunge l'opzione di cercare tra i canali di Discord"
          search: "Ricerca Discord"
        inference:
          name: "Concetti dedotti"
          description: "Classifica argomenti e messaggi per aree di interesse o etichette."
          generate_concepts: "Inferenza dei concetti"
          match_concepts: "Corrispondenza dei concetti"
          deduplicate_concepts: "Deduplicazione dei concetti"
        ai_helper:
          name: "Assistente"
          description: "Assiste gli utenti nelle interazioni con la community, come la creazione di argomenti, la scrittura di messaggi e la lettura di contenuti"
          proofread: Testo corretto
          title_suggestions: "Suggerisci titoli"
          explain: "Spiega"
          illustrate_post: "Illustra messaggio"
          smart_dates: "Date smart"
          translate: "Traduci"
          markdown_tables: "Genera tabella di markdown"
          custom_prompt: "Comando personalizzato"
          image_caption: "Didascalia immagini"
          translator: "Assistente traduzione"
        translation:
          name: "Traduzione"
          description: "Traduce i contenuti nelle lingue supportate"
          locale_detector: "Assistente rilevazione locale"
          post_raw_translator: "Pubblica traduzione grezza"
          topic_title_translator: "Assistente traduzione titolo argomenti"
          short_text_translator: "Assistente traduzione testi brevi"
        spam:
          name: "Spam"
          description: "Identifica lo spam potenziale utilizzando l'LLM selezionato e lo segnala ai moderatori del sito affinché lo ispezionino nella coda di revisione"
          inspect_posts: "Controlla messaggi"
        automation_reports:
          name: "Report automatizzati"
          description: "Crea automaticamente panoramiche concise delle attività, evidenziando tendenze, argomenti chiave e coinvolgimento"
        automation_triage:
          name: "Triage dei messaggi"
          description: "Automatizza la moderazione e la gestione dei messaggi utilizzando regole di automazione configurabili"
      modals:
        select_option: "Scegli un'opzione..."
      layout:
        table: "Tabella"
        card: "Scheda"
      translations:
        title: "Traduzioni"
        progress_chart:
          bar_done:
            one: "%{count} messaggio"
            other: "%{count} messaggi"
      spam:
        short_title: "Spam"
        title: "Configura la gestione dello spam"
        select_llm: "Seleziona LLM"
        select_persona: "Seleziona personaggio"
        custom_instructions: "Istruzioni personalizzate"
        custom_instructions_help: "Istruzioni personalizzate specifiche per il tuo sito per aiutare l'intelligenza artificiale a identificare lo spam, ad esempio \"Sii più aggressivo nell'analizzare i post in una lingua diversa dall'italiano\"."
        last_seven_days: "Ultimi 7 giorni"
        scanned_count: "Messaggi scansionati"
        false_positives: "Segnalato erroneamente"
        false_negatives: "Spam mancato"
        spam_detected: "Spam rilevato"
        custom_instructions_placeholder: "Istruzioni specifiche del sito per l'IA per aiutare a identificare lo spam in modo più accurato"
        enable: "Abilita"
        spam_tip: "Il rilevamento IA dello spam analizzerà i primi 3 messaggi di tutti i nuovi utenti su argomenti pubblici. Li contrassegnerà per la revisione e bloccherà gli utenti se rappresentano verosimilmente spam."
        settings_saved: "Impostazioni salvate"
        spam_description: "Identifica lo spam potenziale utilizzando l'LLM selezionato e lo segnala ai moderatori del sito affinché lo ispezionino nella coda di revisione"
        no_llms: "Nessun LLM disponibile"
        test_button: "Test..."
        save_button: "Salva le modifiche"
        test_modal:
          title: "Prova il rilevamento dello spam"
          post_url_label: "URL o ID del messaggio"
          post_url_placeholder: "https://tuo-forum.com/t/topic/123/4 oppure l'ID del messaggio"
          result: "Risultato"
          scan_log: "Registro di scansione"
          run: "Esegui test"
          spam: "Spam"
          not_spam: "Non è spam"
        stat_tooltips:
          incorrectly_flagged: "Elementi che il bot IA ha contrassegnato come spam su cui i moderatori non erano d'accordo"
          missed_spam: "Elementi segnalati dalla community come spam che non sono stati rilevati dal bot IA, con cui i moderatori hanno concordato"
        errors:
          scan_not_admin:
            message: "Attenzione: la scansione antispam non funzionerà correttamente perché l'account di scansione antispam non è un amministratore"
            action: "Correggi"
          resolved: "L'errore è stato risolto!"
      usage:
        short_title: "Utilizzo"
        summary: "Riepilogo"
        total_tokens: "Totale token"
        tokens_over_time: "Token nel tempo"
        features_breakdown: "Utilizzo per funzionalità"
        feature: "Funzionalità"
        usage_count: "Conteggio utilizzo"
        model: "Modello"
        models_breakdown: "Utilizzo per modello"
        users_breakdown: "Utilizzo per utente"
        all_features: "Tutte le funzionalità"
        all_models: "Tutti i modelli"
        username: "Nome utente"
        total_requests: "Richieste totali"
        request_tokens: "Token di richiesta"
        response_tokens: "Token di risposta"
        net_request_tokens: "Token di richiesta netti"
        cached_tokens: "Token in cache"
        cached_request_tokens: "Token di richiesta memorizzati nella cache"
        total_spending: "Costo stimato"
        no_users: "Nessun dato trovato sull'utilizzo dell'utente"
        no_models: "Nessun dato trovato sull'utilizzo del modello"
        no_features: "Nessun dato trovato sull'utilizzo delle funzionalità"
        subheader_description: "I token sono le unità di base che gli LLM utilizzano per comprendere e generare testo; i dati di utilizzo possono incidere sui costi"
        stat_tooltips:
          total_requests: "Tutte le richieste inoltrate agli LLM tramite Discourse"
          total_tokens: "Tutti i token utilizzati quando si richiede un LLM"
          request_tokens: "Token utilizzati quando l'LLM cerca di capire cosa stai dicendo"
          response_tokens: "Token utilizzati quando l'LLM risponde al tuo comando"
          cached_tokens: "Token di richiesta elaborati in precedenza che LLM riutilizza per ottimizzare prestazioni e costi"
          total_spending: "Costo cumulativo di tutti i token usati dai LLM, in base alle metriche dei costi specificate aggiunte nelle impostazioni di configurazione LLM"
        periods:
          last_day: "Ultime 24 ore"
          last_week: "Ultima settimana"
          last_month: "Ultimo mese"
          custom: "Personalizza..."
      ai_persona:
        ai_tools: "Strumenti"
        tool_strategies:
          all: "Applica a tutte le risposte"
          replies:
            one: "Applica solo alla prima risposta"
            other: "Applica alle prime %{count} risposte"
        back: "Indietro"
        name: "Nome"
        edit: "Modifica"
        export: "Esporta"
        import: "Importa"
        import_error_conflict: "È stato rilevato un conflitto durante l'importazione di %{name}. Vuoi aggiornare il personaggio esistente?"
        overwrite: "Sovrascrivi"
        description: "Descrizione"
        no_llm_selected: "Nessun modello linguistico selezionato"
        use_parent_llm: "Usa modello linguistico personaggi"
        max_context_posts: "Numero massimo di messaggi di contesto"
        max_context_posts_help: "Il numero massimo di post da utilizzare come contesto per l'IA quando si risponde a un utente. (vuoto per impostazione predefinita)"
        vision_enabled: Visione abilitata
        vision_enabled_help: Se l'opzione è abilitata, l'intelligenza artificiale tenterà di comprendere le immagini che gli utenti pubblicano nell'argomento, a seconda del modello utilizzato per supportare la visione. Supportato dagli ultimi modelli di Anthropic, Google e OpenAI.
        vision_max_pixels: Dimensione immagine supportata
        vision_max_pixel_sizes:
          low: 'Bassa qualità: più veloce (256x256)'
          medium: Qualità media (512x512)
          high: 'Alta qualità: più lenta (1024x1024)'
        tool_details: Mostra i dettagli dello strumento
        tool_details_help: Mostrerà agli utenti finali i dettagli su quali strumenti ha attivato il modello linguistico.
        mentionable: Consenti menzioni
        mentionable_help: Se l'opzione è abilitata, gli utenti nei gruppi consentiti possono menzionare questo utente nei post, l'IA risponderà come questa persona.
        user: Utente
        create_user: Crea utente
        create_user_help: Facoltativamente, è possibile associare un utente a questa persona. In tal caso, l'IA utilizzerà questo utente per rispondere alle richieste.
        default_llm: Modello linguistico predefinito
        default_llm_help: Il modello linguistico predefinito da utilizzare per questa persona. Obbligatorio se desideri menzionare la persona nei post pubblici.
        question_consolidator_llm: Modello linguistico per il consolidatore di domande
        question_consolidator_llm_help: Il modello linguistico da utilizzare per il consolidatore di domande. È possibile scegliere un modello meno potente per risparmiare sui costi.
        system_prompt: Comando di sistema
        forced_tool_strategy: Strategia degli strumenti forzati
        allow_chat_direct_messages: "Consenti messaggi diretti in chat"
        allow_chat_direct_messages_help: "Se l'opzione è abilitata, gli utenti nei gruppi consentiti possono inviare messaggi diretti a questa persona."
        allow_chat_channel_mentions: "Consenti menzioni nei canali di chat"
        allow_chat_channel_mentions_help: "Se l'opzione è abilitata, gli utenti nei gruppi consentiti possono menzionare questo personaggio nei canali di chat."
        allow_personal_messages: "Consenti messaggi personali"
        allow_personal_messages_help: "Se l'opzione è abilitata, gli utenti nei gruppi consentiti possono inviare messaggi personali a questo personaggio."
        allow_topic_mentions: "Consenti menzioni nell'argomento"
        allow_topic_mentions_help: "Se l'opzione è abilitata, gli utenti nei gruppi consentiti possono menzionare questa persona negli argomenti."
        force_default_llm: "Usa sempre il modello linguistico predefinito"
        save: "Salva"
        saved: "Persona salvata"
        enabled: "Abilitato?"
        tools: "Strumenti abilitati"
        forced_tools: "Strumenti forzati"
        allowed_groups: "Gruppi ammessi"
        confirm_delete: "Vuoi davvero eliminare questo personaggio?"
        new: "Nuovo personaggio"
        no_personas: "Non hai ancora creato nessun personaggio"
        title: "Personaggi"
        short_title: "Personaggi"
        delete: "Elimina"
        temperature: "Temperatura"
        temperature_help: "Temperatura da utilizzare per LLM. Aumenta per aumentare la creatività (lascia vuoto per utilizzare il modello predefinito, generalmente un valore compreso tra 0,0 e 2,0)"
        top_p: "P superiore"
        top_p_help: "P superiore da utilizzare per LLM, aumenta per aumentare la casualità (lascia vuoto per utilizzare l'impostazione predefinita del modello, generalmente un valore compreso tra 0,0 e 1,0)"
        priority: "Priorità"
        priority_help: "I personaggi prioritari vengono visualizzati agli utenti nella parte superiore dell'elenco dei personaggi. Se più personaggi hanno la priorità, verranno ordinati in ordine alfabetico."
        tool_options: "Opzioni dello strumento"
        rag_conversation_chunks: "Cerca blocchi di conversazione"
        rag_conversation_chunks_help: "Il numero di blocchi da utilizzare per le ricerche del modello RAG. Aumenta per aumentare la quantità di contesto che l'IA può utilizzare."
        persona_description: "I personaggi sono una potente funzionalità che ti consente di personalizzare il comportamento del motore IA nel tuo forum Discourse. Agiscono come un \"messaggio di sistema\" che guida le risposte e le interazioni dell'IA, aiutando a creare un'esperienza utente più personalizzata e coinvolgente."
        response_format:
          title: "Formato di risposta JSON"
          no_format: "Nessun formato JSON specificato"
          open_modal: "Modifica"
          modal:
            root_title: "Struttura di risposta"
            key_title: "Chiave"
        examples:
          title: Esempi
          examples_help: Simula le interazioni precedenti con il LLM e consolidale per ottenere risultati migliori
          new: Nuovo esempio
          remove: Cancella esempio
          collapsable_title: "Esempio #%{number}"
          user: "Messaggio utente"
          model: "Risposta modello"
        list:
          enabled: "Bot IA?"
        ai_bot:
          title: "Opzioni bot IA"
          save_first: "Dopo aver salvato il personaggio, diventeranno disponibili nuove opzioni per il bot IA."
        filters:
          text: "Trova un personaggio"
          reset: "Annulla"
          no_results: "Nessun personaggio trovato per i filtri impostati."
          all_features: "Qualsiasi funzionalità"
        features_list:
          one: "Funzionalità:"
          other: "Funzionalità:"
        llms_list: "LLM:"
      rag:
        title: "RAG"
        options:
          rag_chunk_tokens: "Carica token di blocco"
          rag_chunk_tokens_help: "Il numero di token da utilizzare per ogni blocco nel modello RAG. Aumenta per aumentare la quantità di contesto che l'IA può utilizzare. (La modifica reindicizzerà tutti i caricamenti)"
          rag_chunk_overlap_tokens: "Carica token di sovrapposizione di blocco"
          rag_chunk_overlap_tokens_help: "Il numero di token da sovrapporre tra i blocchi nel modello RAG. (La modifica reindicizzerà tutti i caricamenti)"
          rag_llm_model: "Modello linguistico di indicizzazione"
          rag_llm_model_help: "Il modello linguistico utilizzato per l'OCR durante l'indicizzazione di PDF e immagini"
          show_indexing_options: "Mostra opzioni di caricamento"
          hide_indexing_options: "Nascondi opzioni di caricamento"
        uploads:
          title: "Caricamenti"
          description: "PDF (.pdf), testo normale (.txt) o markdown (.md)"
          description_with_images: "Testo normale (.txt), markdown (.md), PDF (.pdf) o immagine (.png, .jpeg)"
          button: "Aggiungi file"
          filter: "Filtro caricamenti"
          indexed: "Indicizzato"
          indexing: "Indicizzazione"
          uploaded: "Pronto per essere indicizzato"
          uploading: "Caricamento..."
          remove: "Rimuovi caricamento"
      tools:
        back: "Indietro"
        short_title: "Strumenti"
        export: "Esporta"
        import: "Importa"
        import_error_conflict: "Lo strumento è già esistente. Vuoi aggiornarlo?"
        overwrite: "Sovrascrivi"
        no_tools: "Non hai ancora creato nessuno strumento"
        name: "Nome"
        name_help: "Il nome verrà visualizzato nell'interfaccia utente di Discourse e potrai usarlo come identificatore breve per trovare lo strumento in varie impostazioni. Deve essere univoco (condizione obbligatoria)"
        new: "Nuovo strumento"
        tool_name: "Nome strumento"
        tool_name_help: "Il nome dello strumento viene immesso nel LLM. Non è univoco di per sé, ma univoco per personaggio (il personaggio lo convalida all'atto del salvataggio)"
        description: "Descrizione"
        description_help: "Una descrizione chiara dello scopo dello strumento per il modello linguistico"
        subheader_description: "Gli strumenti estendono le capacità dei bot di intelligenza artificiale con funzioni JavaScript definite dall'utente."
        summary: "Riepilogo"
        summary_help: "Il riepilogo degli strumenti ha lo scopo di essere visualizzato agli utenti finali"
        script: "Script"
        parameters: "Parametri"
        save: "Salva"
        parameter_type: "Tipo del parametro"
        add_parameter: "Aggiungi parametro"
        remove_parameter: "Rimuovi"
        parameter_required: "Obbligatorie"
        parameter_enum: "Enumerazione"
        parameter_name: "Nome del parametro"
        parameter_description: "Descrizione del parametro"
        enum_value: "Valore enumerativo"
        add_enum_value: "Aggiungi valore enumerativo"
        edit: "Modifica"
        test: "Esegui test"
        delete: "Elimina"
        saved: "Strumento salvato"
        confirm_delete: "Vuoi davvero eliminare questo strumento?"
        test_modal:
          title: "Prova lo strumento IA"
          run: "Esegui test"
          result: "Risultato del test"
      llms:
        short_title: "LLM"
        no_llms: "Ancora nessun LLM"
        new: "Nuovo modello"
        display_name: "Nome"
        name: "ID modello"
        provider: "Fornitore"
        tokenizer: "Tokenizzatore"
        max_prompt_tokens: "Finestra contestuale"
        max_output_tokens: "Massimo token di output"
        url: "URL del servizio che ospita il modello"
        api_key: "Chiave API del servizio che ospita il modello"
        enabled_chat_bot: "Consenti selettore bot IA"
        vision_enabled: "Visione abilitata"
        ai_bot_user: "Utente bot IA"
        cost_input: "Costo di input"
        cost_cached_input: "Costo di ingresso in cache"
        cost_output: "Costo di output"
        save: "Salva"
        edit: "Modifica"
        saved: "Modello LLM salvato"
        back: "Indietro"
        confirm_delete: Vuoi davvero eliminare questo modello?
        delete: Elimina
        seeded_warning: "Questo modello è preconfigurato sul tuo sito e non può essere modificato."
        quotas:
          title: "Quote di utilizzo"
          add_title: "Crea nuova quota"
          group: "Gruppo"
          max_tokens: "Numero massimo di token"
          max_usages: "Limite max di utilizzi"
          duration: "Durata"
          confirm_delete: "Vuoi davvero eliminare questa quota?"
          add: "Aggiungi quota"
          durations:
            hour: "1 ora"
            six_hours: "6 ore"
            day: "24 ore"
            week: "7 giorni"
            custom: "Personalizza..."
          hours: "ore"
          max_tokens_help: "Numero massimo di token (parole e caratteri) che ogni utente di questo gruppo può utilizzare entro la durata specificata. I token sono le unità utilizzate dai modelli IA per elaborare il testo: circa 1 token = 4 caratteri o 3/4 di parola."
          max_tokens_required: "Deve essere impostato se non è impostato un limite di utilizzo massimo"
          max_usages_help: "Numero massimo di volte in cui ogni utente in questo gruppo può usare il modello IA entro la durata specificata. Questa quota viene tracciata per singolo utente, non condivisa tra il gruppo."
          max_usages_required: "Deve essere impostato se non è impostato un limite di token massimo"
        usage:
          ai_bot: "Bot IA"
          ai_helper: "Assistente (%{persona})"
          ai_helper_image_caption: "Didascalia immagine"
          ai_persona: "Personaggio (%{persona})"
          ai_summarization: "Riassumi"
          ai_embeddings_semantic_search: "Ricerca IA"
          ai_spam: "Spam"
          automation: "Automazione (%{persona})"
        in_use_warning:
          one: "Questo modello è attualmente utilizzato da %{settings}. Se configurato in modo errato, la funzionalità non funzionerà come previsto."
          other: "Questo modello è attualmente utilizzato dai seguenti elementi: %{settings}. Se configurato in modo errato, le funzionalità non funzioneranno come previsto. "
        model_description:
          none: "Impostazioni generali che vanno bene per la maggior parte dei modelli linguistici"
          anthropic-claude-opus-4-1: "Il modello più intelligente di Anthropic"
          anthropic-claude-sonnet-4-0: "Equilibrio ottimale tra velocità e costi"
          anthropic-claude-3-7-sonnet-latest: "Equilibrio ottimale tra velocità e costi (generazione precedente)"
          anthropic-claude-3-5-haiku-latest: "Veloce e conveniente"
          google-gemini-2-5-pro: "Modello multimodale di grandi dimensioni in grado di svolgere un'ampia gamma di attività"
          google-gemini-2-0-flash: "Leggero, veloce ed economicamente efficiente con ragionamento multimodale (generazione precedente)"
          google-gemini-2-5-flash: "Leggero, veloce ed economico con ragionamento multimodale"
          google-gemini-2-0-flash-lite: "Modello economico e a bassa latenza"
          open_ai-o4-mini: "Modello di ragionamento economicamente efficiente avanzato"
          open_ai-gpt-5-mini: "Grazie all'equilibrio tra intelligenza, velocità e costo, è un modello che si presta a numerosi casi d'uso."
          open_ai-gpt-5-nano: "Il modello GPT-5 più veloce ed economicamente efficiente."
          samba_nova-Meta-Llama-3-1-8B-Instruct: "Modello multilingue leggero ed efficiente"
          samba_nova-Meta-Llama-3-3-70B-Instruct": "Potente modello multifunzionale"
          mistral-mistral-large-latest: "Il modello Mistral più potente"
          mistral-pixtral-large-latest: "Il modello Mistral con capacità di visione più potente"
          open_router-x-ai-grok-3-beta: "L'ultimo modello di xAI"
          open_router-deepseek-deepseek-r1-0528-free: "L'ultimo modello di ragionamento di DeepSeek"
          open_router-meta-llama-3-3-70b-instruct: "Modello multilingue di eccellenti capacità"
        preseeded_model_description: "Modello open source preconfigurato che utilizza %{model}"
        configured:
          title: "LLM configurati"
        preconfigured_llms: "Seleziona il tuo LLM"
        preconfigured:
          title_no_llms: "Seleziona un modello per iniziare"
          title: "Modelli LLM non configurati"
          description: "Gli LLM (Large Language Models) sono strumenti di intelligenza artificiale ottimizzati per attività quali la sintesi dei contenuti, la generazione di report, l'automazione delle interazioni con i clienti e la facilitazione della moderazione e degli approfondimenti dei forum"
          fake: "Configurazione manuale"
          button: "Configura"
        next:
          title: "Avanti"
        tests:
          title: "Esegui test"
          running: "Esecuzione del test..."
          success: "Operazione riuscita!"
          failure: "Il tentativo di contattare il modello ha restituito questo errore: %{error}"
        hints:
          max_prompt_tokens: "Il numero massimo di token che il modello può elaborare in una singola richiesta"
          max_output_tokens: "Il numero massimo di token che il modello può generare in una singola richiesta"
          display_name: "Il nome utilizzato per fare riferimento a questo modello nell'interfaccia del sito."
          name: "Lo includiamo nella chiamata API per specificare quale modello utilizzeremo"
          vision_enabled: "Se l'opzione è abilitata, l'intelligenza artificiale tenterà di comprendere le immagini. Dipende dal modello utilizzato per supportare la visione. Supportato dagli ultimi modelli di Anthropic, Google e OpenAI."
          enabled_chat_bot: "Se abilitato, gli utenti possono selezionare questo modello quando creano messaggi privati con il bot IA"
          cost_input: "Il costo di input di 1 milione di token per questo modello"
          cost_cached_input: "Il costo di input di 1 milione di token in cache per questo modello"
          cost_output: "Il costo di output di 1 milione di token per questo modello"
          cost_measure: "$/milione token"
        providers:
          aws_bedrock: "AWS Bedrock"
          anthropic: "Anthropic"
          vllm: "vLLM"
          hugging_face: "Hugging Face"
          cohere: "Cohere"
          open_ai: "OpenAI"
          google: "Google"
          azure: "Azure"
          ollama: "Ollama"
          CDCK: "CDCK"
          samba_nova: "SambaNova"
          mistral: "Mistral"
          open_router: "OpenRouter"
          fake: "Personalizzato"
        provider_fields:
          access_key_id: "ID chiave di accesso AWS Bedrock"
          region: "Regione AWS Bedrock"
          organization: "ID organizzazione OpenAI facoltativo"
          disable_system_prompt: "Disabilita il messaggio di sistema nei comandi"
          enable_native_tool: "Abilita il supporto degli strumenti nativi"
          disable_native_tools: "Disabilita il supporto degli strumenti nativi (utilizza strumenti basati su XML)"
          provider_order: "Ordine fornitori (elenco delimitato da virgole)"
          provider_quantizations: "Ordine delle quantizzazioni dei fornitori (elenco delimitato da virgole, ad esempio: fp16, fp8)"
          disable_streaming: "Disabilita i completamenti dello streaming (converti le richieste di streaming in richieste non di streaming)"
          reasoning_effort: "Sforzo di ragionamento (applicabile solo ai modelli di ragionamento)"
          enable_reasoning: "Abilita ragionamento (applicabile solo ai modelli di ragionamento)"
          enable_thinking: "Abilita pensiero (solo sui modelli applicabili, es. flash 2.5)"
          thinking_tokens: "Numero di token utilizzati per il pensiero"
          reasoning_tokens: "Numero di token utilizzati per il ragionamento"
          disable_temperature: "Disattiva la temperatura (alcuni modelli di pensiero non supportano la temperatura)"
          disable_top_p: "Disattiva la P superiore (alcuni modelli di pensiero non supportano la P superiore)"
          enable_responses_api: "Abilita API risposte (richiesto da alcuni modelli OpenAI)"
      related_topics:
        title: "Argomenti correlati"
        pill: "Correlato"
      ai_helper:
        title: "Suggerisci modifiche utilizzando l'IA"
        description: "Scegli una delle opzioni seguenti e l'IA ti suggerirà una nuova versione del testo."
        selection_hint: "Suggerimento: puoi anche selezionare una parte del testo prima di aprire l'assistente per riscrivere solo quel pezzo."
        suggest: "Suggerisci con l'IA"
        suggest_errors:
          too_many_tags:
            one: "Puoi avere solo fino a %{count} etichetta"
            other: "Puoi avere solo fino a %{count} etichette"
          no_suggestions: "Nessun suggerimento disponibile"
        missing_content: "Inserisci alcuni contenuti per generare suggerimenti."
        context_menu:
          trigger: "Chiedi all'IA"
          loading: "L'IA sta generando"
          cancel: "Annulla"
          regen: "Riprova"
          confirm: "Conferma"
          discard: "Elimina"
          changes: "Modifiche suggerite"
          custom_prompt:
            title: "Comando personalizzato"
            placeholder: "Inserisci un comando personalizzato..."
            submit: "Invia comando"
          translate_prompt: "Traduci in %{language}"
        post_options_menu:
          trigger: "Chiedi all'IA"
          title: "Chiedi all'IA"
          loading: "L'IA sta generando"
          close: "Chiudi"
          copy: "Copia"
          copied: "Copiato!"
          cancel: "Annulla"
          insert_footnote: "Aggiungi nota a piè di pagina"
          footnote_disabled: "Inserimento automatico disabilitato, clicca sul pulsante Copia e modificalo manualmente"
          footnote_credits: "Spiegazione dell'IA"
        fast_edit:
          suggest_button: "Suggerisci modifica"
        thumbnail_suggestions:
          title: "Miniature suggerite"
          select: "Seleziona"
          selected: "Selezionato"
        image_caption:
          button_label: "Didascalia con IA"
          generating: "Generazione didascalia in corso..."
          credits: "Didascalia da IA"
          save_caption: "Salva"
        no_content_error: "Aggiungi prima il contenuto per eseguire azioni IA su di esso"
      reviewables:
        model_used: "Modello utilizzato:"
        accuracy: "Precisione:"
      embeddings:
        short_title: "Integrazioni"
        description: "Le integrazioni sono rappresentazione numeriche in grado di cogliere il significato e le relazioni, rendendo possibile alle funzionalità IA di Discourse come Argomenti correlati e Ricerca IA di comprendere e collegare i contenuti."
        new: "Nuova integrazione"
        back: "Indietro"
        save: "Salva"
        saved: "Configurazione di integrazione salvata"
        delete: "Elimina"
        confirm_delete: Vuoi davvero rimuovere questa configurazione di integrazione?
        empty: "Non hai ancora impostato le integrazioni"
        presets: "Seleziona una preimpostazione..."
        configure_manually: "Configura manualmente"
        edit: "Modifica"
        seeded_warning: "Questo elemento è preconfigurato sul tuo sito e non può essere modificato."
        tests:
          title: "Esegui test"
          running: "Esecuzione del test..."
          success: "Operazione riuscita!"
          failure: "Il tentativo di generare un'integrazione ha prodotto: %{error}"
        hints:
          dimensions_warning: "Una volta salvato, questo valore non può essere modificato."
          matryoshka_dimensions: "Definisce la dimensione delle integrazioni nidificate utilizzate per la rappresentazione gerarchica o multistrato dei dati, in modo simile a come le matrioske si inseriscono l'una nell'altra."
          embed_prompt: "Prefisso per le istruzioni delle attività nella generazione degli embedding ai contenuti dei forum. Valido UNICAMENTE per i modelli di embedding che necessitano di prefissi, come nomic-embed o stella. Superfluo per la maggior parte dei modelli."
          search_prompt: "Prefisso per le istruzioni delle attività nella generazione degli embedding delle query di ricerca. Valido UNICAMENTE per i modelli di embedding che necessitano di prefissi, come nomic-embed o stella. Superfluo per la maggior parte dei modelli."
          sequence_length: "Numero massimo di token che possono essere elaborati contemporaneamente durante la creazione di integrazioni o la gestione di una query."
          distance_function: "Determina come viene calcolata la similarità tra integrazioni, utilizzando la distanza del coseno (misurando l'angolo tra i vettori) o il prodotto interno negativo (misurando la sovrapposizione dei valori dei vettori)."
        display_name: "Nome"
        provider: "Fornitore"
        url: "URL del servizio di integrazione"
        api_key: "Chiave API del servizio di integrazione"
        tokenizer: "Tokenizzatore"
        dimensions: "Dimensioni dell'integrazione"
        max_sequence_length: "Lunghezza della sequenza"
        embed_prompt: "Comando di integrazione"
        search_prompt: "Comando di ricerca"
        matryoshka_dimensions: "Dimensioni della matrioska"
        distance_function: "Funzione di distanza"
        distance_functions:
          "<#>": "Prodotto interno negativo"
          <=>: "Distanza del coseno"
        providers:
          hugging_face: "Hugging Face"
          open_ai: "OpenAI"
          google: "Google"
          cloudflare: "Cloudflare"
          CDCK: "CDCK"
          fake: "Personalizzato"
        provider_fields:
          model_name: "Nome del modello"
        semantic_search: "Argomenti (semantici)"
        semantic_search_loading: "Ricerca di altri risultati tramite intelligenza artificiale"
        semantic_search_results:
          toggle: "Stai vedendo %{count} risultati trovati utilizzando l'IA"
          toggle_hidden: "%{count} risultati trovati utilizzando l'IA sono stati nascosti"
          none: "Spiacenti, la nostra ricerca IA non ha trovato argomenti corrispondenti"
          new: "Premi \"cerca\" per iniziare a cercare nuovi risultati con l'intelligenza artificiale"
          unavailable: "Risultati IA non disponibili"
        semantic_search_tooltips:
          results_explanation: "Se abilitata, verranno aggiunti ulteriori risultati di ricerca IA di seguito."
          invalid_sort: "I risultati della ricerca devono essere ordinati in base alla pertinenza per visualizzare i risultati IA"
        semantic_search_unavailable_tooltip: "I risultati della ricerca devono essere ordinati in base alla pertinenza per visualizzare i risultati IA"
        ai_generated_result: "Risultato della ricerca trovato utilizzando l'intelligenza artificiale"
        quick_search:
          suffix: "in tutti gli argomenti e i post con IA"
      ai_artifact:
        expand_view_label: "Espandi vista"
        collapse_view_label: "Esci dalla modalità a schermo intero (tasto ESC o Indietro)"
        click_to_run_label: "Esegui artefatto"
      ai_bot:
        persona: "Personaggio"
        llm: "Modello"
        pm_warning: "I messaggi del chatbot IA vengono controllati regolarmente dai moderatori."
        cancel_streaming: "Interrompi risposta"
        default_pm_prefix: "[MP di bot IA senza titolo]"
        shortcut_title: "Avvia un MP con un bot IA"
        exit: "esci dal bot AI"
        share: "Copia la conversazione IA"
        conversation_shared: "Conversazione copiata"
        embed_copied: "Incorporamento copiato negli appunti"
        debug_ai: "Visualizza la richiesta e la risposta IA non elaborate"
        sidebar_empty: "La cronologia delle conversazioni con il bot verrà visualizzata qui."
        debug_ai_modal:
          title: "Visualizza l'interazione dell'IA"
          copy_request: "Copia richiesta"
          copy_response: "Copia risposta"
          request_tokens: "Token richieste:"
          response_tokens: "Token risposte:"
          request: "Richiesta"
          response: "Risposta"
          next_log: "Avanti"
          previous_log: "Precedente"
        share_full_topic_modal:
          title: "Condividi la conversazione pubblicamente"
          share: "Condividi e copia il link"
          update: "Aggiorna e copia il link"
          delete: "Elimina condivisione"
        share_ai_conversation:
          name: "Condividi la conversazione con IA"
          title: "Condividi pubblicamente questa conversazione IA"
        invite_ai_conversation:
          button: "Invita"
          title: "Invito a conversare con l'IA"
        ai_label: "IA"
        ai_title: "Conversazione con IA"
        share_modal:
          title: "Copia la conversazione IA"
          copy: "Copia"
          context: "Interazioni da condividere:"
          share_tip: "In alternativa, puoi condividere l'intera conversazione"
        bot_names:
          fake: "Bot di prova finto"
          claude-3-opus: "Claude 3 Opus"
          claude-3-sonnet: "Claude 3 Sonnet"
          claude-3-haiku: "Claude 3 Haiku"
          cohere-command-r-plus: "Cohere Command R Plus"
          gpt-4: "GPT-4"
          gpt-4-turbo: "GPT-4 Turbo"
          gpt-4o: "GPT-4 Omni"
          gpt-3:
            5-turbo: "GPT-3.5"
          claude-2: "Claude 2"
          gemini-1:
            5-pro: "Gemini"
          mixtral-8x7B-Instruct-V0:
            "1": "Mixtral-8x7B V0.1"
        conversations:
          header: "Come posso aiutarti?"
          submit: "Invia domanda"
          disclaimer: "L'IA generativa può sbagliarsi. Verifica sempre le informazioni importanti."
          placeholder: "Fai una domanda..."
          new: "Nuova domanda"
          min_input_length_message:
            one: "Il messaggio deve contenere %{count} carattere o più"
            other: "Il messaggio deve contenere %{count} o più caratteri"
          messages_sidebar_title: "Conversazioni"
          today: "Oggi"
          last_7_days: "Ultimi 7 giorni"
          last_30_days: "Ultimi 30 giorni"
          upload_files: "Carica file"
          uploads_in_progress: "Impossibile caricare mentre sono in corso altri caricamenti"
      sentiments:
        dashboard:
          title: "Sentimento"
        sidebar:
          overview: "Panoramica del sentimento"
          analysis: "Analisi del sentimento"
        sentiment_analysis:
          share_chart: "Copia il link al grafico"
          filter_types:
            all: "Tutti"
            positive: "Positivo"
            neutral: "Neutro"
            negative: "Negativo"
          group_types:
            category: "Categoria"
            tag: "Etichetta"
          table:
            sentiment: "Sentimento"
            total_count: "Totale"
      summarization:
        chat:
          title: "Riassumi i messaggi"
          description: "Seleziona un'opzione qui sotto per riepilogare la conversazione inviata nel periodo di tempo desiderato."
          summarize: "Riassumi"
          since:
            one: "Ultima ora"
            other: "Ultime %{count} ore"
        topic:
          title: "Riepilogo dell'argomento"
          close: "Chiudi il pannello riassuntivo"
        topic_list_layout:
          button:
            compact: "Compatto"
            expanded: "Espanso"
            expanded_description: "con riepiloghi IA"
      discobot_discoveries:
        main_title: "Scoperte del discobot"
        regular_results: "Argomenti"
        tell_me_more: "Dimmi di più..."
        continue_convo: "Continua la conversazione..."
        loading_convo: "Caricamento conversazione"
        collapse: "Comprimi"
        timed_out: "Il discobot non ha trovato scoperte. Si è verificato un errore."
        user_setting: "Abilita le scoperte nella ricerca"
        tooltip:
          header: "Ricerca con IA"
          content: "Ricerca in linguaggio naturale basata su %{model}"
          actions:
            info: "Come funziona?"
            disable: "Disabilita"
      user_preferences:
        empty: "Al momento non sono disponibili impostazioni rilevanti"
    review:
      types:
        reviewable_ai_post:
          title: "Messaggio contrassegnato da IA"
        reviewable_ai_chat_message:
          title: "Messaggio di chat contrassegnato da IA"
